{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python imports\n",
    "import os\n",
    "import yaml\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# algo imports\n",
    "from policy_random import Policy_Random\n",
    "from data_manipulation import get_indices\n",
    "from helper_funcs import create_env\n",
    "\n",
    "prt = False\n",
    "\n",
    "# load params file\n",
    "yaml_path = os.path.abspath('yaml_files/ant_trajfollow.yaml')\n",
    "with open(yaml_path, 'r') as f:\n",
    "    params = yaml.load(f)\n",
    "\n",
    "# print values in param file    \n",
    "for key, value in params.iteritems():\n",
    "    if prt:\n",
    "        print '\\n', key, value\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save params from specified file\n",
    "which_agent = params['which_agent']\n",
    "follow_trajectories = params['follow_trajectories']\n",
    "\n",
    "#data collection\n",
    "use_threading = False #params['data_collection']['use_threading']\n",
    "num_rollouts_train = params['data_collection']['num_rollouts_train']\n",
    "num_rollouts_val = params['data_collection']['num_rollouts_val']\n",
    "\n",
    "#dynamics model\n",
    "num_fc_layers = params['dyn_model']['num_fc_layers']\n",
    "depth_fc_layers = params['dyn_model']['depth_fc_layers']\n",
    "batchsize = params['dyn_model']['batchsize']\n",
    "lr = params['dyn_model']['lr']\n",
    "nEpoch = params['dyn_model']['nEpoch']\n",
    "fraction_use_new = params['dyn_model']['fraction_use_new']\n",
    "\n",
    "#controller\n",
    "horizon = params['controller']['horizon']\n",
    "num_control_samples = params['controller']['num_control_samples']\n",
    "if(which_agent==1):\n",
    "    #if(args.desired_traj_type=='straight'): # I just uncomment this line...\n",
    "    # you can chose the trajectory as straight, left_turn, right_turn, etc...\n",
    "    num_control_samples=3000\n",
    "        \n",
    "#aggregation\n",
    "num_aggregation_iters = params['aggregation']['num_aggregation_iters']\n",
    "num_trajectories_for_aggregation = params['aggregation']['num_trajectories_for_aggregation']\n",
    "rollouts_forTraining = params['aggregation']['rollouts_forTraining']\n",
    "\n",
    "#noise\n",
    "make_aggregated_dataset_noisy = params['noise']['make_aggregated_dataset_noisy']\n",
    "make_training_dataset_noisy = params['noise']['make_training_dataset_noisy']\n",
    "noise_actions_during_MPC_rollouts = params['noise']['noise_actions_during_MPC_rollouts']\n",
    "\n",
    "#steps\n",
    "dt_steps = params['steps']['dt_steps']\n",
    "steps_per_episode = params['steps']['steps_per_episode']\n",
    "steps_per_rollout_train = params['steps']['steps_per_rollout_train']\n",
    "steps_per_rollout_val = params['steps']['steps_per_rollout_val']\n",
    "\n",
    "#saving\n",
    "min_rew_for_saving = params['saving']['min_rew_for_saving']\n",
    "\n",
    "#generic\n",
    "visualize_True = params['generic']['visualize_True']\n",
    "visualize_False = params['generic']['visualize_False']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build directory in order to save all collected data\n",
    "save_dir = 'run_'+ str(0) #str(args.run_num) # this was commented out - just increase the num: 0, 1, 2, ...\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "    os.makedirs(save_dir+'/losses')\n",
    "    os.makedirs(save_dir+'/models')\n",
    "    os.makedirs(save_dir+'/saved_forwardsim')\n",
    "    os.makedirs(save_dir+'/saved_trajfollow')\n",
    "    os.makedirs(save_dir+'/training_data')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set variables\n",
    "np.random.seed(0)\n",
    "tf.set_random_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#more vars\n",
    "x_index, y_index, z_index, yaw_index, joint1_index, joint2_index, frontleg_index, frontshin_index, frontfoot_index, xvel_index, orientation_index = get_indices(which_agent)\n",
    "tf_datatype = tf.float64\n",
    "noiseToSignal = 0.01\n",
    "\n",
    "# n is noisy, c is clean... 1st letter is what action's executed and 2nd letter is what action's aggregated\n",
    "actions_ag='nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 30 31\n"
     ]
    }
   ],
   "source": [
    "print x_index, y_index, z_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "######## save param values to a file ############\n",
    "#################################################\n",
    "\n",
    "param_dict={}\n",
    "param_dict['which_agent']= which_agent\n",
    "param_dict['use_existing_training_data']= False # str(args.use_existing_training_data) - I comment this out\n",
    "param_dict['desired_traj_type']= 'straight' # args.desired_traj_type - I comment this out\n",
    "param_dict['visualize_MPC_rollout']= False # str(args.visualize_MPC_rollout) - I comment this out\n",
    "param_dict['num_rollouts_save_for_mf']= 60 # args.num_rollouts_save_for_mf - I comment this out\n",
    "param_dict['seed']= 0 # args.seed - I comment this out\n",
    "param_dict['follow_trajectories']= str(follow_trajectories)\n",
    "param_dict['use_threading']= str(use_threading)\n",
    "param_dict['num_rollouts_train']= num_rollouts_train\n",
    "param_dict['num_fc_layers']= num_fc_layers\n",
    "param_dict['depth_fc_layers']= depth_fc_layers\n",
    "param_dict['batchsize']= batchsize\n",
    "param_dict['lr']= lr\n",
    "param_dict['nEpoch']= nEpoch\n",
    "param_dict['fraction_use_new']= fraction_use_new\n",
    "param_dict['horizon']= horizon\n",
    "param_dict['num_control_samples']= num_control_samples\n",
    "param_dict['num_aggregation_iters']= num_aggregation_iters\n",
    "param_dict['num_trajectories_for_aggregation']= num_trajectories_for_aggregation\n",
    "param_dict['rollouts_forTraining']= rollouts_forTraining\n",
    "param_dict['make_aggregated_dataset_noisy']= str(make_aggregated_dataset_noisy)\n",
    "param_dict['make_training_dataset_noisy']= str(make_training_dataset_noisy)\n",
    "param_dict['noise_actions_during_MPC_rollouts']= str(noise_actions_during_MPC_rollouts)\n",
    "param_dict['dt_steps']= dt_steps\n",
    "param_dict['steps_per_episode']= steps_per_episode\n",
    "param_dict['steps_per_rollout_train']= steps_per_rollout_train\n",
    "param_dict['steps_per_rollout_val']= steps_per_rollout_val\n",
    "param_dict['min_rew_for_saving']= min_rew_for_saving\n",
    "param_dict['x_index']= x_index\n",
    "param_dict['y_index']= y_index\n",
    "param_dict['tf_datatype']= str(tf_datatype)\n",
    "param_dict['noiseToSignal']= noiseToSignal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save params to file\n",
    "with open(save_dir+'/params.pkl', 'wb') as f:\n",
    "    pickle.dump(param_dict, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(save_dir+'/params.txt', 'w') as f:\n",
    "    f.write(json.dumps(param_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\n\\n the dt is: ', 0.02, '\\n\\n')\n",
      "('--------------------------------- \\nState space dimension: ', (125,))\n",
      "('Action space dimension: ', (8,), '\\n -----------------------------------')\n"
     ]
    }
   ],
   "source": [
    "# create environement\n",
    "env, dt_from_xml= create_env(which_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Created a random policy, where actions are selected between ', array([-1., -1., -1., -1., -1., -1., -1., -1.]), ', and ', array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]))\n"
     ]
    }
   ],
   "source": [
    "#create random policy for data collection\n",
    "random_policy = Policy_Random(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
